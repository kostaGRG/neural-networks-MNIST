{"cells":[{"cell_type":"markdown","metadata":{"id":"i2IkbqPR1UXy"},"source":["# **Personal Details**\n","**Full name**: Konstantinos Gerogiannis  \n","**Studies**: Electrical and Computer Engineering, AUTh  \n","**AEM**: 9638  \n","**Email**: kostas.gerogiannis04@gmail.com\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ch25KQV7B1En"},"source":["## **Summary**\n","In this colab, we are comparing the accuracy between the following list of classifiers:  \n","1. KNN classifier (k nearest neighbours) with k=1  \n","2. KNN classifier (k nearest neighbours) with k=3  \n","3. Nearest Centroid classifier  \n","\n","The code below is written in python 3.  \n","\n","The chosen dataset is named MNIST.  \n","MNIST is a famous dataset that contains a variety of handwritten digits from 0 to 9 and it's used to train and test our models. More information about the used dataset can be found here: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)"]},{"cell_type":"markdown","metadata":{"id":"V2wOgJsdCrzZ"},"source":["### **Get MNIST Dataset from Web**"]},{"cell_type":"markdown","metadata":{"id":"T4noOIFeC-5e"},"source":["First, we get the dataset from the above website, using python's _urllib_ library.  \n","These 4 files are getting stored in this colab temporary, until it is closed."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":699,"status":"ok","timestamp":1673448554466,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"oGT7OT18MIy6","outputId":"eb2c7728-e385-44fd-bcdf-208d4efbc815"},"outputs":[{"data":{"text/plain":["('t10k-labels-idx1-ubyte.gz', <http.client.HTTPMessage at 0x7fab0707a760>)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import urllib.request\n","urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n","urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n","urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n","urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n"]},{"cell_type":"markdown","metadata":{"id":"DrZvPIvLEM9J"},"source":["The files we get from the website are compressed, so in this step we use _gzip_ library to extract them and copy their data in 4 new files (unzipped).  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":652,"status":"ok","timestamp":1673448556433,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"nVVHPvypOShr"},"outputs":[],"source":["import gzip\n","import shutil\n","\n","with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f_in:\n","    with open('train-images-idx3-ubyte', 'wb') as f_out:\n","        shutil.copyfileobj(f_in, f_out)\n","with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f_in:\n","    with open('train-labels-idx1-ubyte', 'wb') as f_out:\n","        shutil.copyfileobj(f_in, f_out)\n","with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f_in:\n","    with open('t10k-images-idx3-ubyte', 'wb') as f_out:\n","        shutil.copyfileobj(f_in, f_out)\n","with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f_in:\n","    with open('t10k-labels-idx1-ubyte', 'wb') as f_out:\n","        shutil.copyfileobj(f_in, f_out)"]},{"cell_type":"markdown","metadata":{"id":"ZrXWx0QTEsvs"},"source":["1. Remove the zip files (optional)  \n","2. Make sure that we have installed idx2numpy package that we will use later"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11387,"status":"ok","timestamp":1673448571178,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"kIU82g1SPDGk","outputId":"fe1e72e0-b189-41d7-dedd-ccf5916286cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting idx2numpy\n","  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from idx2numpy) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from idx2numpy) (1.15.0)\n","Building wheels for collected packages: idx2numpy\n","  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7919 sha256=e7a103dadea3ac46d1184756305f96115e133b60dc73a21f20ce0dceacbf8b68\n","  Stored in directory: /root/.cache/pip/wheels/27/40/a8/6447ee4a00cb87e2084e1ef1df5c38433720cc1090be082842\n","Successfully built idx2numpy\n","Installing collected packages: idx2numpy\n","Successfully installed idx2numpy-1.2.3\n"]}],"source":["!rm 'train-images-idx3-ubyte.gz'\n","!rm 'train-labels-idx1-ubyte.gz'\n","!rm 't10k-images-idx3-ubyte.gz'\n","!rm 't10k-labels-idx1-ubyte.gz'\n","\n","!pip install idx2numpy"]},{"cell_type":"markdown","metadata":{"id":"HWwe6m8QFD52"},"source":["### **Import required libraries, create train and test arrays**"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1673448573367,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"9NVzJQ801VKB"},"outputs":[],"source":["import idx2numpy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","\n","train_images = idx2numpy.convert_from_file('train-images-idx3-ubyte')\n","train_labels = idx2numpy.convert_from_file('train-labels-idx1-ubyte')\n","test_images = idx2numpy.convert_from_file('t10k-images-idx3-ubyte')\n","test_labels = idx2numpy.convert_from_file('t10k-labels-idx1-ubyte')"]},{"cell_type":"markdown","metadata":{"id":"iUn_SthBFW1e"},"source":["(Optional)  \n","To test that we have retrieve our data as we wished, we can print the labels of train set, or we can select an image and plot it."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539},"executionInfo":{"elapsed":740,"status":"ok","timestamp":1673448579016,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"lvsDnfxoK90L","outputId":"e9d657c3-0804-442a-aad5-d2a84895922e"},"outputs":[{"name":"stdout","output_type":"stream","text":["       0\n","0      5\n","1      0\n","2      4\n","3      1\n","4      9\n","...   ..\n","59995  8\n","59996  3\n","59997  5\n","59998  6\n","59999  8\n","\n","[60000 rows x 1 columns]\n"]},{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7faafe80ecd0>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["print(pd.DataFrame(train_labels))\n","plt.imshow(train_images[300], cmap = plt.cm.binary)"]},{"cell_type":"markdown","metadata":{"id":"L37twR-kFy0f"},"source":["The numpy arrays that we have already created have 3 dimensions: (N,28,28)  \n","* N is the number of images\n","* (28x28) is the dimensions of each image\n","\n","In order to use the classifiers we wish, we will reshape the above arrays,  \n","from 3 dimensions to 2. (we will flatten each image from 2D to 1D)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1673448586695,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"UsXP6dW95d6g"},"outputs":[],"source":["dims = np.shape(train_images)\n","X_train = train_images.reshape(dims[0],dims[1]*dims[2])\n","y_train = train_labels\n","\n","dims = np.shape(test_images)\n","X_test = test_images.reshape(dims[0],dims[1]*dims[2])\n","y_test = test_labels"]},{"cell_type":"markdown","metadata":{"id":"KuBgLglOMpaQ"},"source":["### **Create classifiers, test model's accuracy**\n"]},{"cell_type":"markdown","metadata":{"id":"0C2bihANLYw1"},"source":["To make our lives easier, we use the functions provided by the python's library _sklearn_ and we import them. N_JOBS is a parameter used for maximum \n","parallelism (quicker results). We create 3 classifiers, those that we have already mentioned and for each one of them, we fit the data of the train sets and after that we use our models to predict the output. Finally, we simply use accuracy score as our metric to compare the 3 different classifiers."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90400,"status":"ok","timestamp":1673448729452,"user":{"displayName":"kostas gerogiannis","userId":"10121367806092713506"},"user_tz":-120},"id":"60dLI3GELg_D","outputId":"524d4aaa-5af9-4222-fbf4-796a92844d9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["KNN CLASSIFIER WITH k=1\n","Model accuracy score: 0.969\n","Model total time: 40.526\n","KNN CLASSIFIER WITH k=3\n","Model accuracy score: 0.972\n","Model total time: 48.351\n","NEAREST CENTROID CLASSIFIER\n","Model accuracy score: 0.820\n","Model total time: 0.136\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n","from sklearn.metrics import accuracy_score\n","N_JOBS = -1\n","\n","# Let's try with 1 only neighbour\n","start = time.time()\n","knn_cls = KNeighborsClassifier(n_neighbors=1,weights='distance',n_jobs=N_JOBS)\n","knn_cls.fit(X_train,y_train)\n","y_predict = knn_cls.predict(X_test)\n","print(\"KNN CLASSIFIER WITH k=1\")\n","print(\"Model accuracy score: %.3f\" % accuracy_score(y_test, y_predict))\n","print(\"Model total time: %.3f\"%(time.time()-start))\n","\n","# And now with 3 neighbours\n","start = time.time()\n","knn_cls2 = KNeighborsClassifier(n_neighbors=3,weights='distance',n_jobs=N_JOBS)\n","knn_cls2.fit(X_train,y_train)\n","y_predict = knn_cls2.predict(X_test)\n","print(\"KNN CLASSIFIER WITH k=3\")\n","print(\"Model accuracy score: %.3f\" % accuracy_score(y_test, y_predict))\n","print(\"Model total time: %.3f\"%(time.time()-start))\n","\n","# Finally, we will see the results using the nearest centroid classifier\n","start = time.time()\n","cls3 = NearestCentroid()\n","cls3.fit(X_train,y_train)\n","y_predict = cls3.predict(X_test)\n","print(\"NEAREST CENTROID CLASSIFIER\")\n","print(\"Model accuracy score: %.3f\" % accuracy_score(y_test, y_predict))\n","print(\"Model total time: %.3f\"%(time.time()-start))"]},{"cell_type":"markdown","metadata":{"id":"kS6au0ArHxCM"},"source":["### **Results**\n","The results from the above comparison can be summed up in the following table:\n","\n","|  Classifier     | Accuracy score | Total time (sec)|\n","| :-----------:   | :-----------:  | :-------:|\n","| KNN with k=1    | 0.969          |40.5|\n","| KNN with k=3    | 0.972          |48.4|\n","| Nearest Centroid| 0.820          |0.1|"]},{"cell_type":"markdown","metadata":{"id":"hxdBJEgbJAKs"},"source":["As we can easily understand, nearest centroid is the less accurate between the 3 classifiers, because this classifier relies on the average pixel's intensity of the image. But the intensity can differ between images of the same digit, as the images are coming from handwritten digits, each digit is written different from person to person.\n","\n","Between the KNN classifiers, we increase the number of neighbours and as we could predict, the accuracy also increases."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
